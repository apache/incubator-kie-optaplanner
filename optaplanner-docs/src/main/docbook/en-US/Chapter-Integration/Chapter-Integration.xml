<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0"
         xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd http://www.w3.org/1999/xlink http://www.docbook.org/xml/5.0/xsd/xlink.xsd"
         xml:base="../" xml:id="integration" xmlns="http://docbook.org/ns/docbook"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xs="http://www.w3.org/2001/XMLSchema"
         xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns="http://docbook.org/ns/docbook">
  <title>Integration</title>

  <section xml:id="integrationOverview">
    <title>Overview</title>

    <para>Planner's input and output data (the planning problem and the best solution) are plain old JavaBeans (POJO's),
    so integration with other Java technologies is straightforward. For example:</para>

    <itemizedlist>
      <listitem>
        <para>To read a planning problem from the database (and store the best solution in it), annotate the domain
        POJO's with JPA annotations.</para>
      </listitem>

      <listitem>
        <para>To read a planning problem from an XML file (and store the best solution in it), annotate the domain
        POJO's with XStream or JAXB annotations.</para>
      </listitem>

      <listitem>
        <para>To expose the Solver as a REST Service that reads the planning problem and responds with the best
        solution, annotate the domain POJO's with XStream, JAXB or Jackson annotations and hook the
        <literal>Solver</literal> in Camel or RESTEasy.</para>
      </listitem>
    </itemizedlist>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Integration/integrationOverview.png"/>
      </imageobject>
    </mediaobject>
  </section>

  <section xml:id="integrationWithPersistentStorage">
    <title>Persistent Storage</title>

    <section xml:id="integrationWithJpaAndHibernate">
      <title>Database: JPA and Hibernate</title>

      <para>Enrich the domain POJO's (solution, entities and problem facts) with JPA annotations to store them in a
      database.</para>

      <note>
        <para>Do not confuse JPA's <literal>@Entity</literal> annotation with Planner's
        <literal>@PlanningEntity</literal> annotation. They can appear both on the same class:</para>

        <programlisting language="java">@PlanningEntity // OptaPlanner annotation
@Entity // JPA annotation
public class Talk {...}</programlisting>
      </note>

      <para>Add a dependency to the <literal>optaplanner-persistence-jpa</literal> jar to take advantage of these extra
      integration features:</para>

      <section xml:id="jpaAndHibernatePersistingAScore">
        <title>JPA and Hibernate: Persisting a <literal>Score</literal></title>

        <para>When a <literal>Score</literal> is persisted into a relational database, JPA and Hibernate will default to
        Java serializing it to a <literal>BLOB</literal> column. This has several disadvantages:</para>

        <itemizedlist>
          <listitem>
            <para>The Java serialization format of <literal>Score</literal> classes is currently not backwards
            compatible. Upgrading to a newer Planner version can break reading an existing database.</para>
          </listitem>

          <listitem>
            <para>The score is not easily readable for a query executed in the database console. This is annoying during
            development.</para>
          </listitem>

          <listitem>
            <para>The score cannot be used in a SQL or JPA-QL query to efficiently filter the results: for example to
            query all infeasible schedules.</para>
          </listitem>
        </itemizedlist>

        <para>To avoid these issues, configure it to instead use INTEGER (or other) columns, by using the appropriate
        <literal>*ScoreHibernateType</literal> for your <literal>Score</literal> type, for example for a
        <literal>HardSoftScore</literal>:</para>

        <programlisting language="java">@PlanningSolution
@Entity
@TypeDef(defaultForType = HardSoftScore.class, typeClass = HardSoftScoreHibernateType.class)
public class CloudBalance {

    @PlanningScore
    @Columns(columns = {@Column(name = "initScore"), @Column(name = "hardScore"), @Column(name = "softScore")})
    protected HardSoftScore score;

    ...
}</programlisting>

        <note>
          <para>Configure the same number of <literal>@Column</literal> annotations as the number of score levels in the
          score plus one (for the <literal>initScore</literal>), otherwise Hibernate will fail fast because a property
          mapping has the wrong number of columns.</para>
        </note>

        <para>In this case, the DDL will look like this:</para>

        <programlisting language="sql">CREATE TABLE CloudBalance(
    ...
    initScore INTEGER,
    hardScore INTEGER,
    softScore INTEGER
);</programlisting>

        <para>When using a <literal>BigDecimal</literal> based <literal>Score</literal>, specify the precision and scale
        of the columns to avoid silent rounding:</para>

        <programlisting language="java">@PlanningSolution
@Entity
@TypeDef(defaultForType = HardSoftBigDecimalScore.class, typeClass = HardSoftBigDecimalScoreHibernateType.class)
public class CloudBalance{

    @PlanningScore
    @Columns(columns = {
            @Column(name = "initScore")
            @Column(name = "hardScore", precision = 10, scale = 5),
            @Column(name = "softScore", precision = 10, scale = 5)})
    protected HardSoftBigDecimalScore score;

    ...
}</programlisting>

        <para>In this case, the DDL will look like this:</para>

        <programlisting language="sql">CREATE TABLE CloudBalance(
    ...
    initScore INTEGER,
    hardScore DECIMAL(10, 5),
    softScore DECIMAL(10, 5)
);</programlisting>

        <para>When using any type of bendable <literal>Score</literal>, specify the hard and soft level sizes as
        parameters:</para>

        <programlisting language="java">@PlanningSolution
@Entity
@TypeDef(defaultForType = BendableScore.class, typeClass = BendableScoreHibernateType.class, parameters = {
        @Parameter(name = "hardLevelsSize", value = "3"),
        @Parameter(name = "softLevelsSize", value = "2")})
public class Schedule {

    @PlanningScore
    @Columns(columns = {
            @Column(name = "initScore")
            @Column(name = "hard0Score"),
            @Column(name = "hard1Score"),
            @Column(name = "hard2Score"),
            @Column(name = "soft0Score"),
            @Column(name = "soft1Score")})
    protected BendableScore score;

    ...
}</programlisting>

        <para>All this support is Hibernate specific because currently JPA 2.1's converters do not support converting to
        multiple columns.</para>
      </section>

      <section xml:id="jpaAndHibernatePlanningCloning">
        <title>JPA and Hibernate: Planning Cloning</title>

        <para>In JPA and Hibernate, there is usually a <literal>@ManyToOne</literal> relationship from most problem fact
        classes to the planning solution class. Therefore, the problem fact classes reference the planning solution
        class, which implies that when the solution is <link linkend="cloningASolution">planning cloned</link>, they
        need to be cloned too. Use an <literal>@DeepPlanningClone</literal> on each such problem fact class to enforce
        that:</para>

        <programlisting language="java">@PlanningSolution // OptaPlanner annotation
@Entity // JPA annotation
public class Conference {

    @OneToMany(mappedBy="conference")
    private List&lt;Room&gt; roomList;

    ...
}</programlisting>

        <programlisting language="java">@DeepPlanningClone // OptaPlanner annotation: Force the default planning cloner to planning clone this class too
@Entity // JPA annotation
public class Room {

    @ManyToOne
    private Conference conference; // Because of this reference, this problem fact needs to be planning cloned too

}</programlisting>

        <para>Neglecting to do this can lead to persisting duplicate solutions, JPA exceptions or other side
        effects.</para>
      </section>
    </section>

    <section xml:id="integrationWithXStream">
      <title>XML or JSON: XStream</title>

      <para>Enrich the domain POJO's (solution, entities and problem facts) with XStream annotations to serialize them
      to/from XML or JSON.</para>

      <para>Add a dependency to the <literal>optaplanner-persistence-xstream</literal> jar to take advantage of these
      extra integration features:</para>

      <section xml:id="xStreamMarshallingAScore">
        <title>XStream: Marshalling a <literal>Score</literal></title>

        <para>When a <literal>Score</literal> is marshalled to XML or JSON by the default XStream configuration, it's
        verbose and ugly. To fix that, configure the appropriate <literal>ScoreXStreamConverter</literal>:</para>

        <programlisting language="java">@PlanningSolution
@XStreamAlias("CloudBalance")
public class CloudBalance {

    @PlanningScore
    @XStreamConverter(HardSoftScoreXStreamConverter.class)
    private HardSoftScore score;

    ...
}</programlisting>

        <para>For example, this will generate pretty XML:</para>

        <programlisting language="xml">&lt;CloudBalance&gt;
   ...
   &lt;score&gt;0hard/-200soft&lt;/score&gt;
&lt;/CloudBalance&gt;</programlisting>

        <para>The same applies for a bendable score:</para>

        <programlisting language="java">@PlanningSolution
@XStreamAlias("Schedule")
public class Schedule {

    @PlanningScore
    @XStreamConverter(BendableScoreXStreamConverter.class)
    private BendableScore score;

    ...
}</programlisting>

        <para>For example, this will generate:</para>

        <programlisting language="xml">&lt;Schedule&gt;
   ...
   &lt;score&gt;[0/0]hard/[-100/-20/-3]soft&lt;/score&gt;
&lt;/Schedule&gt;</programlisting>

        <para>The <literal>hardLevelsSize</literal> and <literal>softLevelsSize</literal> implied, when reading a
        bendable score from an XML element, must always be in sync with those in the solver.</para>
      </section>
    </section>

    <section xml:id="integrationWithJaxb">
      <title>XML or JSON: JAXB</title>

      <para>Enrich the domain POJO's (solution, entities and problem facts) with JAXB annotations to serialize them
      to/from XML or JSON.</para>

      <para>Add a dependency to the <literal>optaplanner-persistence-jaxb</literal> jar to take advantage of these extra
      integration features:</para>

      <section xml:id="jaxbMarshallingAScore">
        <title>JAXB: Marshalling a <literal>Score</literal></title>

        <para>When a <literal>Score</literal> is marshalled to XML or JSON by the default JAXB configuration, it's
        corrupted. To fix that, configure the appropriate <literal>ScoreJaxbXmlAdapter</literal>:</para>

        <programlisting language="java">@PlanningSolution
@XmlRootElement @XmlAccessorType(XmlAccessType.FIELD)
public class CloudBalance {

    @PlanningScore
    @XmlJavaTypeAdapter(HardSoftScoreJaxbXmlAdapter.class)
    private HardSoftScore score;

    ...
}</programlisting>

        <para>For example, this will generate pretty XML:</para>

        <programlisting language="xml">&lt;cloudBalance&gt;
   ...
   &lt;score&gt;0hard/-200soft&lt;/score&gt;
&lt;/cloudBalance&gt;</programlisting>

        <para>The same applies for a bendable score:</para>

        <programlisting language="java">@PlanningSolution
@XmlRootElement @XmlAccessorType(XmlAccessType.FIELD)
public class Schedule {

    @PlanningScore
    @XmlJavaTypeAdapter(BendableScoreJaxbXmlAdapter.class)
    private BendableScore score;

    ...
}</programlisting>

        <para>For example, with a <literal>hardLevelsSize</literal> of <literal>2</literal> and a
        <literal>softLevelsSize</literal> of <literal>3</literal>, that will generate:</para>

        <programlisting language="xml">&lt;schedule&gt;
   ...
   &lt;score&gt;[0/0]hard/[-100/-20/-3]soft&lt;/score&gt;
&lt;/schedule&gt;</programlisting>

        <para>The <literal>hardLevelsSize</literal> and <literal>softLevelsSize</literal> implied, when reading a
        bendable score from an XML element, must always be in sync with those in the solver.</para>
      </section>
    </section>

    <section xml:id="integrationWithJackson">
      <title>JSON: Jackson</title>

      <para>Enrich the domain POJO's (solution, entities and problem facts) with Jackson annotations to serialize them
      to/from JSON.</para>

      <para>Add a dependency to the <literal>optaplanner-persistence-jackson</literal> jar to take advantage of these
      extra integration features:</para>

      <section xml:id="jacksonMarshallingAScore">
        <title>JAXB: Marshalling a <literal>Score</literal></title>

        <para>When a <literal>Score</literal> is marshalled to JSON by the default Jackson configuration, it fails. To
        fix that, configure a <literal>ScoreJacksonJsonSerializer</literal> and the appropriate
        <literal>ScoreJacksonJsonDeserializer</literal>:</para>

        <programlisting language="java">@PlanningSolution
public class CloudBalance {

    @PlanningScore
    @JsonSerialize(using = ScoreJacksonJsonSerializer.class)
    @JsonDeserialize(using = HardSoftScoreJacksonJsonDeserializer.class)
    private HardSoftScore score;

    ...
}</programlisting>

        <para>For example, this will generate pretty JSON:</para>

        <programlisting language="json">{
   ...
   "score":"0hard/-200soft"
}</programlisting>

        <para>The same applies for a bendable score:</para>

        <programlisting language="java">@PlanningSolution
public class Schedule {

    @PlanningScore
    @JsonSerialize(using = ScoreJacksonJsonSerializer.class)
    @JsonDeserialize(using = BendableScoreJacksonXmlAdapter.class)
    private BendableScore score;

    ...
}</programlisting>

        <para>For example, with a <literal>hardLevelsSize</literal> of <literal>2</literal> and a
        <literal>softLevelsSize</literal> of <literal>3</literal>, that will generate:</para>

        <programlisting language="json">{
   ...
   "score":"[0/0]hard/[-100/-20/-3]soft"
}</programlisting>

        <para>The <literal>hardLevelsSize</literal> and <literal>softLevelsSize</literal> implied, when reading a
        bendable score from a JSON element, must always be in sync with those in the solver.</para>
      </section>
    </section>
  </section>

  <section xml:id="integrationWithSoaAndEsb">
    <title>SOA and ESB</title>

    <section xml:id="integrationWithCamel">
      <title>Camel and Karaf</title>

      <para><link xlink:href="http://camel.apache.org/">Camel</link> is an enterprise integration framework which
      includes support for Planner (starting from Camel 2.13). It can expose a use case as a REST service, a SOAP
      service, a JMS service, ...</para>

      <para><link xlink:href="http://camel.apache.org/optaplanner.html">Read the documentation for the camel-optaplanner
      component.</link> That component works in Karaf too.</para>
    </section>
  </section>

  <section xml:id="integrationWithOtherEnvironments">
    <title>Other Environments</title>

    <section xml:id="integrationWithJBossModules">
      <title>JBoss Modules, WildFly and JBoss EAP</title>

      <para>To deploy an Planner web application on WildFly, simply include the optaplanner dependency jars in the
      <literal>war</literal> file's <literal>WEB-INF/lib</literal> directory (just like any other dependency) as shown
      in the <literal>optaplanner-webexamples-*.war</literal>. However, in this approach the war file can easily grow to
      several MB in size, which is fine for a one-time deployment, but too heavyweight for frequent redeployments
      (especially over a slow network connection).</para>

      <para>The remedy is to use deliver the optaplanner jars in a JBoss module to WildFly and create a skinny war.
      Let's create an module called <emphasis>org.optaplanner</emphasis>:</para>

      <orderedlist>
        <listitem>
          <para>Navigate to the directory <literal role="bold">${WILDFLY_HOME}/modules/system/layers/base/</literal>.
          This directory contains the JBoss modules of WildFly. Create directory structure
          <literal>org/optaplanner/main</literal> for our new module.</para>

          <orderedlist>
            <listitem>
              <para>Copy <literal>optaplanner-core-${version}.jar</literal> and all its direct and transitive dependency
              jars into that new directory. Use "mvn dependency:tree" on each optaplanner artifact to discover all
              dependencies.</para>
            </listitem>

            <listitem>
              <para>Create the file <literal>module.xml</literal> in that new directory. Give it this content:</para>

              <programlisting language="xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;module xmlns="urn:jboss:module:1.3" name="org.optaplanner"&gt;
  &lt;resources&gt;
    ...
    &lt;resource-root path="kie-api-${version}.jar"/&gt;
    ...
    &lt;resource-root path="optaplanner-core-${version}.jar"/&gt;
    ...
    &lt;resource-root path="."/&gt; 
  &lt;/resources&gt;
  &lt;dependencies&gt;
    &lt;module name="javaee.api"/&gt;
  &lt;/dependencies&gt;
&lt;/module&gt;</programlisting>
            </listitem>
          </orderedlist>
        </listitem>

        <listitem>
          <para>Navigate to the deployed <literal>war</literal> file.</para>

          <orderedlist>
            <listitem>
              <para>Remove <literal>optaplanner-core-${version}.jar</literal> and all its direct and transitive
              dependency jars from the <literal>WEB-INF/lib</literal> directory in the <literal>war</literal>
              file.</para>
            </listitem>

            <listitem>
              <para>Create the file <literal>jboss-deployment-structure.xml</literal> in the
              <literal>WEB-INF/lib</literal> directory. Give it this content:</para>

              <programlisting language="xml">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;jboss-deployment-structure&gt;
   &lt;deployment&gt;
      &lt;dependencies&gt;
         &lt;module name="org.optaplanner" export="true"/&gt;
      &lt;/dependencies&gt;
   &lt;/deployment&gt;
&lt;/jboss-deployment-structure&gt;</programlisting>
            </listitem>
          </orderedlist>
        </listitem>
      </orderedlist>

      <para>Because of JBoss Modules' <literal>ClassLoader</literal> magic, you'll likely need to provide the
      <literal>ClassLoader</literal> of your classes <link linkend="solverConfigurationByXML">during the SolverFactory
      creation</link>, so it can find the classpath resources (such as the solver config, score DRL's and domain
      classes) in your jars.</para>
    </section>

    <section xml:id="integrationWithOSGi">
      <title>OSGi</title>

      <para>The <literal>optaplanner-core</literal> jar includes OSGi metadata in its <literal>MANIFEST.MF</literal>
      file to function properly in an OSGi environment too. Furthermore, the maven artifact
      <literal>kie-karaf-features</literal> contains a <literal>features.xml</literal> file that supports
      the OSGi-feature <literal>optaplanner-engine</literal>.</para>

      <para>Because of the OSGi's <literal>ClassLoader</literal> magic, you'll likely need to provide the
      <literal>ClassLoader</literal> of your classes <link linkend="solverConfigurationByXML">during the SolverFactory
      creation</link>, so it can find the classpath resources (such as the solver config, score DRL's and domain
      classes) in your jars.</para>

      <note>
        <para>Planner does <emphasis>not</emphasis> require OSGi. It works perfectly fine in a normal Java environment
        too.</para>
      </note>
    </section>

    <section xml:id="integrationWithAndroid">
      <title>Android</title>

      <para>Android is not a complete JVM (because some JDK libraries are missing), but Planner works on Android with
      <link linkend="easyJavaScoreCalculation">easy Java</link> or <link
      linkend="incrementalJavaScoreCalculation">incremental Java</link> score calculation. The Drools rule engine does
      not work on Android yet, so Drools score calculation doesn't work on Android and its dependencies need to be
      excluded.</para>

      <para><emphasis role="bold">Workaround to use Planner on Android:</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Add a dependency to the <literal>build.gradle</literal> file in your Android project to exclude
          <literal>org.drools</literal> and <literal>xmlpull</literal> dependencies:</para>

          <programlisting language="gradle">dependencies {
    ...
    compile('org.optaplanner:optaplanner-core:...') {
        exclude group: 'xmlpull'
        exclude group: 'org.drools'
    }
    ...
}</programlisting>
        </listitem>
      </orderedlist>
    </section>
  </section>

  <section xml:id="integrationWithHumanPlanners">
    <title>Integration with Human Planners (Politics)</title>

    <para>A good Planner implementation beats any good human planner for non-trivial datasets. Many human planners fail
    to accept this, often because they feel threatened by an automated system.</para>

    <para>But despite that, both can benefit if the human planner becomes the supervisor of Planner:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">The human planner defines and validates the score function.</emphasis></para>

        <itemizedlist>
          <listitem>
            <para>Some examples expose a <literal>*Parametrization</literal> object, which defines the weight for each
            score constraint. The human planner can then tweak those weights at runtime.</para>
          </listitem>

          <listitem>
            <para>When the business changes, the score function often needs to change too. The human planner can notify
            the developers to add, change or remove score constraints.</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para><emphasis role="bold">The human planner is always in control of Planner.</emphasis></para>

        <itemizedlist>
          <listitem>
            <para>As shown in the course scheduling example, the human planner can lock 1 or more planning variables to
            a specific planning value and make those immovable. Because they are <link
            linkend="immovablePlanningEntities">immovable</link>, Planner does not change them: it optimizes the
            planning around the enforcements made by the human. If the human planner locks all planning variables,
            he/she sidelines Planner completely.</para>
          </listitem>

          <listitem>
            <para>In a prototype implementation, the human planner might use this occasionally. But as the
            implementation matures, it must become obsolete. But do keep the feature alive: as a reassurance for the
            humans. Or in case that one day the business changes dramatically before the score constraints can be
            adjusted.</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>

    <para>Therefore, it's often a good idea to involve the human planner in your project.</para>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Integration/parameterizeTheScoreWeights.png"/>
      </imageobject>
    </mediaobject>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Integration/keepTheUserInControl.png"/>
      </imageobject>
    </mediaobject>
  </section>

  <section xml:id="sizingHardwareAndSoftware">
    <title>Sizing Hardware and Software</title>

    <para>Before sizing a Planner service, first understand the typical behaviour of a <literal>Solver.solve()</literal>
    call:</para>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Integration/sizingHardware.png"/>
      </imageobject>
    </mediaobject>

    <para>Understand these guidelines to decide the hardware for a Planner service:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">RAM memory</emphasis>: Provision plenty, but no need to provide more.</para>

        <itemizedlist>
          <listitem>
            <para>The problem dataset, loaded before Planner is called, often consumes the most memory. It depends on
            the problem scale.</para>

            <itemizedlist>
              <listitem>
                <para>For example, in the Machine Reassignment example some datasets use over 1GB in memory. But in most
                examples, they use just a few MB.</para>
              </listitem>

              <listitem>
                <para>If this is a problem, review the domain class structure: remove classes or fields that Planner
                doesn't need during solving.</para>
              </listitem>

              <listitem>
                <para>Planner usually has up to 3 solution instances: the internal working solution, the best solution
                and the old best solution (when it's being replaced). However, these are all a <link
                linkend="cloningASolution">planning clone</link> of each other, so many problem fact instances are
                shared between those solution instances.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>During solving, the memory is very volatile, because solving creates many short-lived objects. The
            Garbage Collector deletes these in bulk and therefore needs some heap space as a buffer.</para>
          </listitem>

          <listitem>
            <para>The maximum size of the JVM heap space can be in 3 states:</para>

            <itemizedlist>
              <listitem>
                <para><emphasis role="bold">Insufficient</emphasis>: An <literal>OutOfMemoryException</literal> is
                thrown (often because the Garbage Collector is using more than 98% of the CPU time).</para>
              </listitem>

              <listitem>
                <para><emphasis role="bold">Narrow</emphasis>: The heap buffer for those short-lived instances is too
                small, therefore the Garbage Collector needs to run more than it would like to, which causes a
                performance loss.</para>

                <itemizedlist>
                  <listitem>
                    <para>Profiling shows that in the heap chart, the used heap space frequently touches the max heap
                    space during solving. It also shows that the Garbage Collector has a significant CPU usage
                    impact.</para>
                  </listitem>

                  <listitem>
                    <para>Adding more heap space increases the <link linkend="scoreCalculationSpeed">score calculation
                    speed</link>.</para>
                  </listitem>
                </itemizedlist>
              </listitem>

              <listitem>
                <para><emphasis role="bold">Plenty</emphasis>: There is enough heap space. The Garbage Collector is
                active, but its CPU usage is low.</para>

                <itemizedlist>
                  <listitem>
                    <para>Adding more heap space does <emphasis>not</emphasis> increase performance.</para>
                  </listitem>

                  <listitem>
                    <para>Usually, this is around 300 to 500MB above the dataset size, <emphasis>regardless of the
                    problem scale</emphasis> (except with <link linkend="nearbySelection">nearby selection</link> and
                    caching move selector, neither are used by default).</para>
                  </listitem>
                </itemizedlist>
              </listitem>
            </itemizedlist>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para><emphasis role="bold">CPU power</emphasis>: More is better.</para>

        <itemizedlist>
          <listitem>
            <para>Improving CPU speed directly increases the <link linkend="scoreCalculationSpeed">score calculation
            speed</link>.</para>

            <itemizedlist>
              <listitem>
                <para>If the CPU power is twice as fast, it takes half the time to find the same result. However, this
                does not guarantee that it finds a better result in the same time, nor that it finds a similar result
                for a problem twice as a big in the same time.</para>
              </listitem>

              <listitem>
                <para>Increasing CPU power usually does not resolve scaling issues, because planning problems scale
                exponentially. Power tweaking the solver configuration has far better results for scaling issues than
                throwing hardware at it.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>During the <literal>solve()</literal> method, the CPU power will max out until it returns (except in
            <link linkend="daemon">daemon mode</link> or if your <link
            linkend="SolverEventListener">SolverEventListener</link> writes the best solution to disk or the
            network).</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para><emphasis role="bold">Number of CPU cores</emphasis>: 1 CPU core per active Solver, plus at least one 1
        for the operating system.</para>

        <itemizedlist>
          <listitem>
            <para>So in a multitenant application, which has 1 Solver per tenant, this means 1 CPU core per tenant,
            unless the number of solver threads is limited, as that limits the number of tenants being solved in
            parallel.</para>
          </listitem>

          <listitem>
            <para>With Partitioned Search, presume 1 CPU core per partition (per active tenant), unless the number of
            partition threads is limited.</para>

            <itemizedlist>
              <listitem>
                <para>To reduce the number of used cores, it can be better to reduce the partition threads (so solve
                some partitions sequentially) than to reduce the number of partitions.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>In use cases with many tenants (such as scheduling Software as a Service) or many partitions, it might
            not be affordable to provision that many CPU's.</para>

            <itemizedlist>
              <listitem>
                <para>Reduce the number of active Solvers at a time. For example: give each tenant only 1 minute of
                machine time and use a <literal>ExecutorService</literal> with a fixed thread pool to queue
                requests.</para>
              </listitem>

              <listitem>
                <para>Distribute the Solver runs across the day (or night). This is especially an opportunity in SaaS
                that's used across the globe, due to timezones: UK and India can use the same CPU core when scheduling
                at night.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>The SolverManager will take care of the orchestration, especially in those underfunded environments in
            which solvers (and partitions) are forced to share CPU cores or wait in line.</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para><emphasis role="bold">I/O (network, disk, ...)</emphasis>: Not used during solving.</para>

        <itemizedlist>
          <listitem>
            <para>Planner is not a web server: a solver thread does not block (unlike a servlet thread), each one fully
            drains a CPU.</para>

            <itemizedlist>
              <listitem>
                <para>A web server can handle 24 active servlets threads with 8 cores without performance loss, because
                most servlets threads are blocking on I/O.</para>
              </listitem>

              <listitem>
                <para>However, 24 active solver threads with 8 cores will cause each solver's <link
                linkend="scoreCalculationSpeed">score calculation speed</link> to be 3 times slower, causing a big
                performance loss.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>Note that calling any I/O during solving, for example a remote service in your score calculation,
            causes a huge performance loss because it's called thousands of times per second, so it should complete in
            microseconds. So no good implementation does that.</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>

    <para>Keep these guidelines in mind when selecting and configuring the software. See <link
    xlink:href="http://www.optaplanner.org/blog/archive.html">our blog archive</link> for the details of our
    experiments, which use our diverse set of examples. Your mileage may vary.</para>

    <itemizedlist>
      <listitem>
        <para>Operating System</para>

        <itemizedlist>
          <listitem>
            <para>No experimentally proven advice yet (but prefer Linux anyway).</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>JDK</para>

        <itemizedlist>
          <listitem>
            <para>Version: Java 7 can be between 10% and 25% faster than Java 6. But Java 8 however is usually not
            significantly faster than Java 7.</para>
          </listitem>

          <listitem>
            <para>Garbage Collector: ParallelGC (the default in Java 8) can be potentially between 5% and 35% faster
            than G1GC (the default in Java 9). Unlike web servers, Planner needs a GC focused on throughput, not
            latency. Use <literal>-XX:+UseParallelGC</literal> to turn on ParallelGC.</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>Logging can have a severe impact on performance.</para>

        <itemizedlist>
          <listitem>
            <para>Debug logging <literal>org.drools</literal> can reduce performance by a factor of 7.</para>
          </listitem>

          <listitem>
            <para>Debug logging <literal>org.optaplanner</literal> can be between 0% and 15% slower than info logging.
            Trace logging can be between 5% and 70% slower than info logging.</para>
          </listitem>

          <listitem>
            <para>Synchronous logging to a file has an additional significant impact for debug and trace logging (but
            not for info logging).</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>Avoid a cloud environment in which you share your CPU core(s) with other virtual machines or containers.
        Performance (and therefore solution quality) can be unreliable when the available CPU power varies
        greatly.</para>
      </listitem>
    </itemizedlist>

    <para>Keep in mind that the perfect hardware/software environment will probably <emphasis>not</emphasis> solve
    scaling issues (even Moore's law is too slow). There is no need to follow these guidelines to the letter.</para>
  </section>
</chapter>
