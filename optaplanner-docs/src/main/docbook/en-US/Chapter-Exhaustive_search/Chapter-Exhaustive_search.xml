<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0"
         xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd http://www.w3.org/1999/xlink http://www.docbook.org/xml/5.0/xsd/xlink.xsd"
         xml:base="../" xml:id="exhaustiveSearch" xmlns="http://docbook.org/ns/docbook"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xs="http://www.w3.org/2001/XMLSchema"
         xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns="http://docbook.org/ns/docbook">
  <title>Exhaustive search</title>

  <section>
    <title>Overview</title>

    <para>Exact methods will always find the global optimum and recognize it too. That being said, they don't scale (not
    even beyond toy data sets) and are therefore mostly useless.</para>
  </section>

  <section xml:id="bruteForce">
    <title>Brute Force</title>

    <section>
      <title>Algorithm description</title>

      <para>The Brute Force algorithm creates and evaluates every possible solution.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/Chapter-Exhaustive_search/bruteForceNQueens04.png"/>
        </imageobject>
      </mediaobject>

      <para>Notice that it creates a search tree that explodes exponentially as the problem size increases, so it hits a
      scalability wall.</para>

      <important>
        <para><emphasis role="bold">Brute Force is mostly unusable for a real-world problem due to time
        limitations</emphasis>, as shown in <link linkend="scalabilityOfExhaustiveSearch">scalability of Exhaustive
        Search</link>.</para>
      </important>
    </section>

    <section>
      <title>Configuration</title>

      <para>Simplest configuration of Brute Force:</para>

      <programlisting language="xml">&lt;solver&gt;
  ...
  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRUTE_FORCE&lt;/exhaustiveSearchType&gt;
  &lt;/exhaustiveSearch&gt;
&lt;/solver&gt;</programlisting>
    </section>
  </section>

  <section xml:id="branchAndBound">
    <title>Branch And Bound</title>

    <section>
      <title>Algorithm description</title>

      <para>Branch And Bound also explores nodes in an exponential search tree, but it investigates more promising nodes
      first and prunes away worthless nodes.</para>

      <para>For each node, Branch And Bound calculates the optimistic bound: the best possible score to which that node
      can lead to. If the optimistic bound of a node is lower or equal to the global pessimistic bound, then it prunes
      away that node (including the entire branch of all its subnodes).</para>

      <note>
        <para>Academic papers use the term lower bound instead of optimistic bound (and the term upper bound instead of
        pessimistic bound), because they minimize the score.</para>

        <para>OptaPlanner maximizes the score (because it supports combining negative and positive constraints).
        Therefore, for clarity, OptaPlanner uses different terms, as it would be confusing to use the term lower bound
        for a bound which is always higher.</para>
      </note>

      <para>For example: at index 15, it can prune away all unvisited solutions with queen A on row 0, because none will
      be better than the solution of index 14 with a score of <literal>-1</literal>.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/Chapter-Exhaustive_search/depthFirstBranchAndBoundNQueens04.png"/>
        </imageobject>
      </mediaobject>

      <para>Notice that Branch And Bound (much like Brute Force) creates a search tree that explodes exponentially as
      the problem size increases. So it hits the same scalability wall, only a little bit later.</para>

      <important>
        <para><emphasis role="bold">Branch And Bound is mostly unusable for a real-world problem due to time
        limitations</emphasis>, as shown in <link linkend="scalabilityOfExhaustiveSearch">scalability of Exhaustive
        Search</link>.</para>
      </important>
    </section>

    <section>
      <title>Configuration</title>

      <para>Simplest configuration of Branch And Bound:</para>

      <programlisting language="xml">&lt;solver&gt;
  ...
  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
  &lt;/exhaustiveSearch&gt;
&lt;/solver&gt;</programlisting>

      <important>
        <para>For the pruning to work with the default <literal>ScoreBounder</literal>, the <link
        linkend="initializingScoreTrend">InitializingScoreTrend</link> should be set. Especially an <link
        linkend="initializingScoreTrend">InitializingScoreTrend</link> of <literal>ONLY_DOWN</literal> (or at least has
        <literal>ONLY_DOWN</literal> in the leading score levels) prunes a lot.</para>
      </important>

      <para>Advanced configuration:</para>

      <programlisting language="xml">  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
    &lt;nodeExplorationType&gt;DEPTH_FIRST&lt;/nodeExplorationType&gt;
    &lt;entitySorterManner&gt;DECREASING_DIFFICULTY_IF_AVAILABLE&lt;/entitySorterManner&gt;
    &lt;valueSorterManner&gt;INCREASING_STRENGTH_IF_AVAILABLE&lt;/valueSorterManner&gt;
  &lt;/exhaustiveSearch&gt;</programlisting>

      <para>The <literal>nodeExplorationType</literal> options are:</para>

      <itemizedlist>
        <listitem>
          <para><literal>DEPTH_FIRST</literal> (default): Explore deeper nodes first (and then a better score and then a
          better optimistic bound). Deeper nodes (especially leaf nodes) often improve the pessimistic bound. A better
          pessimistic bound allows pruning more nodes to reduce the search space.</para>

          <programlisting language="xml">  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
    &lt;nodeExplorationType&gt;DEPTH_FIRST&lt;/nodeExplorationType&gt;
  &lt;/exhaustiveSearch&gt;</programlisting>
        </listitem>

        <listitem>
          <para><literal>BREADTH_FIRST</literal> (not recommended): Explore nodes layer by layer (and then a better
          score and then a better optimistic bound). Scales terribly in memory (and usually in performance too).</para>

          <programlisting language="xml">  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
    &lt;nodeExplorationType&gt;BREADTH_FIRST&lt;/nodeExplorationType&gt;
  &lt;/exhaustiveSearch&gt;</programlisting>
        </listitem>

        <listitem>
          <para><literal>SCORE_FIRST</literal>: Explore nodes with a better score first (and then a better optimistic
          bound and then deeper nodes first). Might scale as terribly as <literal>BREADTH_FIRST</literal> in some
          cases.</para>

          <programlisting language="xml">  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
    &lt;nodeExplorationType&gt;SCORE_FIRST&lt;/nodeExplorationType&gt;
  &lt;/exhaustiveSearch&gt;</programlisting>
        </listitem>

        <listitem>
          <para><literal>OPTIMISTIC_BOUND_FIRST</literal>: Explore nodes with a better optimistic bound first (and then
          a better score and then deeper nodes first). Might scale as terribly as <literal>BREADTH_FIRST</literal> in
          some cases.</para>

          <programlisting language="xml">  &lt;exhaustiveSearch&gt;
    &lt;exhaustiveSearchType&gt;BRANCH_AND_BOUND&lt;/exhaustiveSearchType&gt;
    &lt;nodeExplorationType&gt;OPTIMISTIC_BOUND_FIRST&lt;/nodeExplorationType&gt;
  &lt;/exhaustiveSearch&gt;</programlisting>
        </listitem>
      </itemizedlist>

      <para>The <literal>entitySorterManner</literal> options are:</para>

      <itemizedlist>
        <listitem>
          <para><literal>DECREASING_DIFFICULTY</literal>: Initialize the more difficult planning entities first. This
          usually increases pruning (and therefore improves scalability). Requires the model to support <link
          linkend="planningEntityDifficulty">planning entity difficulty comparison</link>.</para>
        </listitem>

        <listitem>
          <para><literal>DECREASING_DIFFICULTY_IF_AVAILABLE</literal> (default): If the model supports <link
          linkend="planningEntityDifficulty">planning entity difficulty comparison</link>, behave like
          <literal>DECREASING_DIFFICULTY</literal>, else like <literal>NONE</literal>.</para>
        </listitem>

        <listitem>
          <para><literal>NONE</literal>: Initialize the planning entities in original order.</para>
        </listitem>
      </itemizedlist>

      <para>The <literal>valueSorterManner</literal> options are:</para>

      <itemizedlist>
        <listitem>
          <para><literal>INCREASING_STRENGTH</literal>: Try the planning values in increasing strength. Requires the
          model to support <link linkend="planningValueStrength">planning value strength comparison</link>.</para>
        </listitem>

        <listitem>
          <para><literal>INCREASING_STRENGTH_IF_AVAILABLE</literal> (default): If the model supports <link
          linkend="planningValueStrength">planning value strength comparison</link>, behave like
          <literal>INCREASING_STRENGTH</literal>, else like <literal>NONE</literal>.</para>
        </listitem>

        <listitem>
          <para><literal>NONE</literal>: Try the planning values in original order.</para>
        </listitem>
      </itemizedlist>
    </section>
  </section>

  <section xml:id="scalabilityOfExhaustiveSearch">
    <title>Scalability of Exhaustive Search</title>

    <para>Exhaustive Search variants suffer from 2 big scalability issues:</para>

    <itemizedlist>
      <listitem>
        <para>They scale terribly memory wise.</para>
      </listitem>

      <listitem>
        <para>They scale horribly performance wise.</para>
      </listitem>
    </itemizedlist>

    <para>As shown in these time spent graphs from the <link linkend="benchmarkingAndTweaking">Benchmarker</link>, Brute
    Force and Branch And Bound both hit a performance scalability wall. For example, on N queens it hits wall at a few
    dozen queens:</para>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Exhaustive_search/exhaustiveSearchScalabilityNQueens.png"/>
      </imageobject>
    </mediaobject>

    <para>In most use cases, such as Cloud Balancing, the wall appears out of thin air:</para>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/Chapter-Exhaustive_search/exhaustiveSearchScalabilityCloudBalance.png"/>
      </imageobject>
    </mediaobject>

    <para><emphasis role="bold">Exhaustive Search hits this wall on small datasets already, so in production these
    optimizations algorithms are mostly useless.</emphasis> Use Construction Heuristics with Local Search instead: those
    can handle thousands of queens/computers easily.</para>

    <note>
      <para>Throwing hardware at these scalability issues has no noticeable impact. Newer and more hardware are just a
      drop in the ocean. Moore's law cannot win against the onslaught of a few more planning entities in the
      dataset.</para>
    </note>
  </section>
</chapter>
